{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The primary purpose of this notebook is to test the OpenEphys sorting \"pipeline\".\n",
    "Specifically, after defining your pathnames appropriately, this notebook will use SpikeInterface to perform spike sorting, analyze the sorting quality, and exports the results in \"Phy\" format. This output is then passed into pyramid to extract behavioral data, eye data, and spiking data to create a \"TrialFile\" which can be easily converted in Matlab to a user-friendly format, like FIRA, to perform subsequent analyses.**\n",
    "\n",
    "Notes: \n",
    "1) MAKE SURE YOUR KERNEL (top right corner of the notebook in VS Code) IS \"gold_pipelines (Python X.XX.X)\n",
    "2) This should be run with VS code when your top level folder is \\Lab_Pipelines/experiments/aodr/\n",
    "3) Can't find a module/package? Check if you have a jupyter conflict. If your jupyter notebook is local, it's looking for resources based on the local jupyter paths. We want our jupyter notebook to be working in the same environment we're using (gold_pipelines). This might pose problems for other work you do with jupyter, but I'm not sure yet (you might want to consider only installing jupyter in python environments). Check which jupyter you're using by typing \"which jupyter\" in a terminal with the gold_pipelines environment activated. If it references a jupyer that is located in \".../anaconda3/envs/gold_pipelines\" then you should be okay. If it's something else then you should try uninstalling jupyter:\n",
    "\n",
    "```python\n",
    "conda remove jupyter jupyter-client jupyter-console jupyter-core\n",
    "\n",
    "conda uninstall jupyter_core nbformat nbconvert notebook\n",
    "```\n",
    "\n",
    "Then reinstall the gold_pipelines environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.widgets as sw\n",
    "from AODR_session_sorters import OpenEphysSessionSorter as OES\n",
    "from pyramid import cli\n",
    "import pandas as pd\n",
    "import sys, os, io\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define the relevant paths. You should change these to match the corresponding paths on your machine. If you encounter issues while loading/sorting the file, chances are that your computer is having a hard time accessing the files from cloud storage. If that is the case, you need to transfer your files to a local directory, and also save the files to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment directory top level - should contain the subfolders like ecodes, python, matlab.\n",
    "expDir = \"C:\\\\Users\\\\GoldLab\\\\OneDrive\\\\Documents\\\\GitHub\\\\Lab_Pipelines\\\\experiments\\\\aodr\"\n",
    "os.chdir(expDir) # regular python files will run from the first open folder in your tree, but notebooks will work from wherever the notebook is stored.\n",
    "# Directory where the raw files are stored to be converted\\\\sorted\n",
    "#dataSearchPath = \"C:\\\\Users\\\\GoldLab\\\\Box\\\\GoldLab\\\\Data\\\\Physiology\\\\AODR\\\\Data\\\\Anubis\\\\Raw\\\\Behavior\\\\\"\n",
    "dataSearchPath = \"C:\\\\Users\\\\GoldLab\\\\Downloads\\\\\" # test file\n",
    "# Where the rules for ecodes are stored\n",
    "pyramidSearchPath = expDir+\"\\\\ecodes\"\n",
    "# Conversion specifications\n",
    "convertSpecs = expDir+\"\\\\AODR_experiment_LC.yaml\"\n",
    "# Base directory to save the output files from pyramid (hdf5 files)\n",
    "#baseSaveDir = \"C:\\\\Users\\\\GoldLab\\\\Box\\\\GoldLab\\\\Data\\\\Physiology\\\\AODR\\\\Data\\\\Anubis\\\\Converted\\\\Behavior\\\\Pyramid\\\\\"\n",
    "baseSaveDir = \"C:\\\\Users\\\\GoldLab\\\\Documents\\\\Output_Test\\\\\" # test output folder\n",
    "# The Open Ephys session directory (technically not a file, but a folder)\n",
    "#currentFile = \"Anubis_2024-08-05_12-06-56\"\n",
    "currentFile = \"sub-255CR_ses-20200322T135448_behavior+ecephys+image.nwb\"\n",
    "# Full directory to save the output files from pyramid (hdf5 files)\n",
    "trialFileOutputName = baseSaveDir+currentFile+\".hdf5\"\n",
    "# Directory to save the output files from sorting\n",
    "#sorted_out = dataSearchPath.split(\"Raw\")[0]+\"Sorted\\\\\"+currentFile\n",
    "sorted_out = baseSaveDir\n",
    "\n",
    "sys.path.append(expDir+\"\\\\python\") # to make sure pyramid can access the custom collectors/enhancers/functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we run the sorter/analyzer. With ~4 channels of neural data and a 90 min recording, this should take between 10-20 minutes. The step_names variable defines the sequential processing steps that are defined as methods in AODR_session_sorters OpenEphysSessionSorter class. If you use the step \"open_sigui\", a gui window will open that allows to interact with the sorting results. Close the gui to continue to the next step and save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_tree ...OK\n",
      "read_data ...OK\n",
      "set_linear ...OK\n",
      "bandpass ...OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kilosort.run_kilosort: Kilosort version 4.0.32\n",
      "kilosort.run_kilosort: Python version 3.11.12\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: System information:\n",
      "kilosort.run_kilosort: Windows-10-10.0.26100-SP0 AMD64\n",
      "kilosort.run_kilosort: Intel64 Family 6 Model 151 Stepping 2, GenuineIntel\n",
      "kilosort.run_kilosort: Using CPU for PyTorch computations. Specify `device` to change this.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: Sorting C:\\Users\\GoldLab\\Documents\\Output_Test\\data.bin\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage before sorting\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:     9.30 %\n",
      "kilosort.run_kilosort: Mem used:     43.10 %     |      27.47 GB\n",
      "kilosort.run_kilosort: Mem avail:    36.26 / 63.73 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing preprocessing variables.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "c:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\kilosort\\io.py:635: RuntimeWarning: \n",
      "                <class 'numpy.int16'> is not supported and may result in unexpected\n",
      "                behavior or errors. Supported types are:\n",
      "\n",
      "                ['int16', 'uint16', 'int32', 'float32']\n",
      "                \n",
      "  warnings.warn(message, RuntimeWarning)\n",
      "kilosort.run_kilosort: N samples: 65480704\n",
      "kilosort.run_kilosort: N seconds: 2182.6903747897736\n",
      "kilosort.run_kilosort: N batches: 1092\n",
      "kilosort.run_kilosort: Preprocessing filters computed in  1.66s; total  1.68s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after preprocessing\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    35.00 %\n",
      "kilosort.run_kilosort: Mem used:     43.40 %     |      27.65 GB\n",
      "kilosort.run_kilosort: Mem avail:    36.08 / 63.73 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Computing drift correction.\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "c:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\kilosort\\io.py:635: RuntimeWarning: \n",
      "                <class 'numpy.int16'> is not supported and may result in unexpected\n",
      "                behavior or errors. Supported types are:\n",
      "\n",
      "                ['int16', 'uint16', 'int32', 'float32']\n",
      "                \n",
      "  warnings.warn(message, RuntimeWarning)\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "c:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "kilosort.spikedetect: Number of universal templates: 125\n",
      "kilosort.spikedetect: Detecting spikes...\n",
      "100%|██████████| 1092/1092 [15:46<00:00,  1.15it/s]\n",
      "kilosort.run_kilosort: drift computed in  994.27s; total  995.98s\n",
      "c:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\kilosort\\io.py:635: RuntimeWarning: \n",
      "                <class 'numpy.int16'> is not supported and may result in unexpected\n",
      "                behavior or errors. Supported types are:\n",
      "\n",
      "                ['int16', 'uint16', 'int32', 'float32']\n",
      "                \n",
      "  warnings.warn(message, RuntimeWarning)\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after drift correction\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    37.60 %\n",
      "kilosort.run_kilosort: Mem used:     43.70 %     |      27.83 GB\n",
      "kilosort.run_kilosort: Mem avail:    35.90 / 63.73 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Extracting spikes using templates\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.spikedetect: Re-computing universal templates from data.\n",
      "kilosort.spikedetect: Number of universal templates: 125\n",
      "kilosort.spikedetect: Detecting spikes...\n",
      "100%|██████████| 1092/1092 [16:36<00:00,  1.10it/s]\n",
      "kilosort.run_kilosort: 901879 spikes extracted in  1042.45s; total  2038.49s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: First clustering\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|██████████| 1/1 [03:34<00:00, 214.58s/it]\n",
      "kilosort.run_kilosort: 196 clusters found, in  214.85s; total  2253.34s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Extracting spikes using cluster waveforms\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|██████████| 1092/1092 [22:01<00:00,  1.21s/it]\n",
      "kilosort.run_kilosort: 2302462 spikes extracted in  1321.48s; total  3574.82s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after spike detection\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    14.50 %\n",
      "kilosort.run_kilosort: Mem used:     45.10 %     |      28.74 GB\n",
      "kilosort.run_kilosort: Mem avail:    34.99 / 63.73 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Final clustering\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "100%|██████████| 1/1 [09:11<00:00, 551.89s/it]\n",
      "kilosort.run_kilosort: 170 clusters found, in  551.90s; total  4126.77s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Merging clusters\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: 165 units found, in  1.04s; total  4127.81s\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after clustering\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    50.60 %\n",
      "kilosort.run_kilosort: Mem used:     45.10 %     |      28.75 GB\n",
      "kilosort.run_kilosort: Mem avail:    34.99 / 63.73 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Saving to phy and computing refractory periods\n",
      "kilosort.run_kilosort: ----------------------------------------\n",
      "kilosort.run_kilosort: 40 units found with good refractory periods\n",
      "kilosort.run_kilosort: Total runtime: 4134.27s = 01:08:54 h:m:s\n",
      "kilosort.run_kilosort: Sorting output saved in: C:\\Users\\GoldLab\\Documents\\Output_Test\\kilosort4.\n",
      "kilosort.run_kilosort:  \n",
      "kilosort.run_kilosort: Resource usage after saving\n",
      "kilosort.run_kilosort: ********************************************************\n",
      "kilosort.run_kilosort: CPU usage:    16.30 %\n",
      "kilosort.run_kilosort: Mem used:     45.80 %     |      29.21 GB\n",
      "kilosort.run_kilosort: Mem avail:    34.52 / 63.73 GB\n",
      "kilosort.run_kilosort: ------------------------------------------------------\n",
      "kilosort.run_kilosort: GPU usage:    N/A\n",
      "kilosort.run_kilosort: GPU memory:   N/A\n",
      "kilosort.run_kilosort: ********************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_kilosort ...OK\n"
     ]
    }
   ],
   "source": [
    "sorter = OES(session_dir=dataSearchPath+currentFile, channel_names=list(range(0, 63)),\n",
    "             out_folder=sorted_out,\n",
    "             sorter_name='kilosort4',\n",
    "             step_names=[\n",
    "                 #'clean_tree',                      # This removes everything from the output folder!!!\n",
    "                 'read_data',                       # Has to be included to do anything else\n",
    "                 'set_linear',\n",
    "                 'bandpass',\n",
    "                 'run_kilosort4_demo'\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_tree ...OK\n",
      "read_data ...OK\n",
      "set_linear ...OK\n",
      "bandpass ...OK\n",
      "installation_mode='auto' switching to installation_mode: 'github'\n",
      "Docker: pulling image spikeinterface/kilosort4-base\n",
      "Starting container\n",
      "Installing spikeinterface with github in container\n",
      "Installing h5py with pypi in container\n",
      "Running kilosort4 sorter inside spikeinterface/kilosort4-base\n",
      "Stopping container\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sorted_out = \u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mGoldLab\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mDocuments\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mDocker_Output_Test\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sorter = \u001b[43mOES\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataSearchPath\u001b[49m\u001b[43m+\u001b[49m\u001b[43mcurrentFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_names\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m63\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m             \u001b[49m\u001b[43mout_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msorted_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m             \u001b[49m\u001b[43msorter_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkilosort4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m             \u001b[49m\u001b[43mstep_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                 \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclean_tree\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# This removes everything from the output folder!!!\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m                 \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mread_data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# Has to be included to do anything else\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m                 \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mset_linear\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                 \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbandpass\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                 \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrun_kilosort4_and_analyzer\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                 \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopen_sigui\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Opens a gui to view the sorting results to help with manual refinement\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m                 \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexport_to_phy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Currently pyramid supports Phy output or plexon\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m             \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\OneDrive\\Documents\\GitHub\\Lab_Pipelines\\experiments\\aodr\\python\\AODR_session_sorters.py:76\u001b[39m, in \u001b[36mOpenEphysSessionSorter.__init__\u001b[39m\u001b[34m(self, session_dir, stream_name, channel_names, step_names, result_name, sorter_name, out_folder, freq_min, freq_max)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.step_names:\n\u001b[32m     75\u001b[39m     func = \u001b[38;5;28mself\u001b[39m.\u001b[34m__getattribute__\u001b[39m(step)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     done = \u001b[33m'\u001b[39m\u001b[33m...OK\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mprint\u001b[39m(step, done)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\OneDrive\\Documents\\GitHub\\Lab_Pipelines\\experiments\\aodr\\python\\AODR_session_sorters.py:201\u001b[39m, in \u001b[36mOpenEphysSessionSorter.run_kilosort4_and_analyzer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m params = si.get_default_sorter_params(\u001b[33m'\u001b[39m\u001b[33mkilosort4\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    198\u001b[39m \u001b[38;5;28mself\u001b[39m.sorting = si.run_sorter(\u001b[33m'\u001b[39m\u001b[33mkilosort4\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m.recording,\n\u001b[32m    199\u001b[39m                                     folder=\u001b[38;5;28mself\u001b[39m.out_folder+\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m+\u001b[38;5;28mself\u001b[39m.sorter_name, \n\u001b[32m    200\u001b[39m                                     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m, docker_image=\u001b[38;5;28;01mTrue\u001b[39;00m, **params)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28mself\u001b[39m.sorting_analyzer = \u001b[43msi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_sorting_analyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msorting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbinary_folder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_folder\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/analyzer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mjob_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\spikeinterface\\core\\sortinganalyzer.py:152\u001b[39m, in \u001b[36mcreate_sorting_analyzer\u001b[39m\u001b[34m(sorting, recording, format, folder, sparse, sparsity, return_scaled, overwrite, backend_options, **sparsity_kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m np.array_equal(\n\u001b[32m    149\u001b[39m         recording.channel_ids, sparsity.channel_ids\n\u001b[32m    150\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33mcreate_sorting_analyzer(): if external sparsity is given unit_ids must correspond\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sparse:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     sparsity = \u001b[43mestimate_sparsity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msparsity_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    154\u001b[39m     sparsity = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\spikeinterface\\core\\sparsity.py:820\u001b[39m, in \u001b[36mestimate_sparsity\u001b[39m\u001b[34m(sorting, recording, num_spikes_for_sparsity, ms_before, ms_after, method, peak_sign, radius_um, num_channels, threshold, amplitude_mode, by_property, noise_levels, **job_kwargs)\u001b[39m\n\u001b[32m    817\u001b[39m spikes = sorting.to_spike_vector()\n\u001b[32m    818\u001b[39m spikes = spikes[random_spikes_indices]\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m templates_array = \u001b[43mestimate_templates_with_accumulator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspikes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m    \u001b[49m\u001b[43msorting\u001b[49m\u001b[43m.\u001b[49m\u001b[43munit_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnbefore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnafter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_scaled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mestimate_sparsity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mjob_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m templates = Templates(\n\u001b[32m    831\u001b[39m     templates_array=templates_array,\n\u001b[32m    832\u001b[39m     sampling_frequency=recording.sampling_frequency,\n\u001b[32m   (...)\u001b[39m\u001b[32m    837\u001b[39m     probe=probe,\n\u001b[32m    838\u001b[39m )\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mbest_channels\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\spikeinterface\\core\\waveform_tools.py:866\u001b[39m, in \u001b[36mestimate_templates_with_accumulator\u001b[39m\u001b[34m(recording, spikes, unit_ids, nbefore, nafter, return_scaled, job_name, return_std, verbose, **job_kwargs)\u001b[39m\n\u001b[32m    862\u001b[39m     job_name = \u001b[33m\"\u001b[39m\u001b[33mestimate_templates_with_accumulator\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    863\u001b[39m processor = ChunkRecordingExecutor(\n\u001b[32m    864\u001b[39m     recording, func, init_func, init_args, job_name=job_name, verbose=verbose, need_worker_index=\u001b[38;5;28;01mTrue\u001b[39;00m, **job_kwargs\n\u001b[32m    865\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;66;03m# average\u001b[39;00m\n\u001b[32m    869\u001b[39m waveforms_sum = np.sum(waveform_accumulator_per_worker, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\site-packages\\spikeinterface\\core\\job_tools.py:517\u001b[39m, in \u001b[36mChunkRecordingExecutor.run\u001b[39m\u001b[34m(self, recording_slices)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;66;03m# parallel\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(\n\u001b[32m    504\u001b[39m     max_workers=n_jobs,\n\u001b[32m    505\u001b[39m     initializer=process_worker_initializer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    515\u001b[39m     ),\n\u001b[32m    516\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_function_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecording_slices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    519\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.progress_bar:\n\u001b[32m    520\u001b[39m         results = tqdm(\n\u001b[32m    521\u001b[39m             results, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.job_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (workers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_jobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m processes)\u001b[39m\u001b[33m\"\u001b[39m, total=\u001b[38;5;28mlen\u001b[39m(recording_slices)\n\u001b[32m    522\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\concurrent\\futures\\process.py:837\u001b[39m, in \u001b[36mProcessPoolExecutor.map\u001b[39m\u001b[34m(self, fn, timeout, chunksize, *iterables)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize < \u001b[32m1\u001b[39m:\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mchunksize must be >= 1.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m results = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_process_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m_get_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\concurrent\\futures\\_base.py:608\u001b[39m, in \u001b[36mExecutor.map\u001b[39m\u001b[34m(self, fn, timeout, chunksize, *iterables)\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    606\u001b[39m     end_time = timeout + time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m fs = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult_iterator\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\concurrent\\futures\\_base.py:608\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    606\u001b[39m     end_time = timeout + time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m fs = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*iterables)]\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult_iterator\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\concurrent\\futures\\process.py:808\u001b[39m, in \u001b[36mProcessPoolExecutor.submit\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28mself\u001b[39m._executor_manager_thread_wakeup.wakeup()\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._safe_to_dynamically_spawn_children:\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adjust_process_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;28mself\u001b[39m._start_executor_manager_thread()\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\concurrent\\futures\\process.py:767\u001b[39m, in \u001b[36mProcessPoolExecutor._adjust_process_count\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    759\u001b[39m process_count = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._processes)\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m process_count < \u001b[38;5;28mself\u001b[39m._max_workers:\n\u001b[32m    761\u001b[39m     \u001b[38;5;66;03m# Assertion disabled as this codepath is also used to replace a\u001b[39;00m\n\u001b[32m    762\u001b[39m     \u001b[38;5;66;03m# worker that unexpectedly dies, even when using the 'fork' start\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    765\u001b[39m     \u001b[38;5;66;03m# we know a thread is running (self._executor_manager_thread).\u001b[39;00m\n\u001b[32m    766\u001b[39m     \u001b[38;5;66;03m#assert self._safe_to_dynamically_spawn_children or not self._executor_manager_thread, 'https://github.com/python/cpython/issues/90622'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m767\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_spawn_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\concurrent\\futures\\process.py:785\u001b[39m, in \u001b[36mProcessPoolExecutor._spawn_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_spawn_process\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    778\u001b[39m     p = \u001b[38;5;28mself\u001b[39m._mp_context.Process(\n\u001b[32m    779\u001b[39m         target=_process_worker,\n\u001b[32m    780\u001b[39m         args=(\u001b[38;5;28mself\u001b[39m._call_queue,\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m               \u001b[38;5;28mself\u001b[39m._initargs,\n\u001b[32m    784\u001b[39m               \u001b[38;5;28mself\u001b[39m._max_tasks_per_child))\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m     \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m     \u001b[38;5;28mself\u001b[39m._processes[p.pid] = p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\multiprocessing\\context.py:336\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     94\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     97\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\GoldLab\\anaconda3\\envs\\gold_pipelines\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sorted_out = \"C:\\\\Users\\\\GoldLab\\\\Documents\\\\Docker_Output_Test\\\\\"\n",
    "sorter = OES(session_dir=dataSearchPath+currentFile, channel_names=list(range(0, 63)),\n",
    "             out_folder=sorted_out,\n",
    "             sorter_name='kilosort4',\n",
    "             step_names=[\n",
    "                 #'clean_tree',                      # This removes everything from the output folder!!!\n",
    "                 'read_data',                       # Has to be included to do anything else\n",
    "                 'set_linear',\n",
    "                 'bandpass',\n",
    "                 'run_kilosort4_and_analyzer',\n",
    "                 'open_sigui',                      # Opens a gui to view the sorting results to help with manual refinement\n",
    "                 'export_to_phy'                    # Currently pyramid supports Phy output or plexon\n",
    "             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike interface has a lot of widgets availble to use with python jupyter notebooks. These widgets are interactive and useful, and the below code will test whether they are working appropriately on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_filt = sw.plot_spikes_on_traces(sorter.sorting_analyzer, channel_ids=[2], backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run Pyramid on the corresponding output to create a TrialFile. Make sure that the phy_reader.params_file points to the appropriate directory based on those you have defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli.main([\"convert\", \n",
    "        \"--trial-file\", trialFileOutputName, \n",
    "        \"--search-path\", pyramidSearchPath, \n",
    "        \"--experiment\", convertSpecs, \n",
    "        \"--readers\", \n",
    "        \"ttl_reader.session_dir=\"+dataSearchPath+currentFile,\n",
    "        \"message_reader.session_dir=\"+dataSearchPath+currentFile,\n",
    "        \"gaze_x_reader.session_dir=\"+dataSearchPath+currentFile,\n",
    "        \"gaze_y_reader.session_dir=\"+dataSearchPath+currentFile,\n",
    "        \"pupil_reader.session_dir=\"+dataSearchPath+currentFile,\n",
    "        \"phy_reader.params_file=\"+sorted_out+\"/phy/params.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gold_pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
