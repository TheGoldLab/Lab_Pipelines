{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The primary purpose of this notebook is to test the OpenEphys sorting \"pipeline\".\n",
    "Specifically, after defining your pathnames appropriately, this notebook will use SpikeInterface to perform spike sorting, analyze the sorting quality, and exports the results in \"Phy\" format. This output is then passed into pyramid to extract behavioral data, eye data, and spiking data to create a \"TrialFile\" which can be easily converted in Matlab to a user-friendly format, like FIRA, to perform subsequent analyses.**\n",
    "\n",
    "Notes: \n",
    "1) MAKE SURE YOUR KERNEL (top right corner of the notebook in VS Code) IS \"gold_pipelines (Python X.XX.X)\n",
    "2) This should be run with VS code when your top level folder is /Lab_Pipelines/experiments/aodr/\n",
    "3) Can't find a module/package? Check if you have a jupyter conflict. If your jupyter notebook is local, it's looking for resources based on the local jupyter paths. We want our jupyter notebook to be working in the same environment we're using (gold_pipelines). This might pose problems for other work you do with jupyter, but I'm not sure yet (you might want to consider only installing jupyter in python environments). Check which jupyter you're using by typing \"which jupyter\" in a terminal with the gold_pipelines environment activated. If it references a jupyer that is located in \".../anaconda3/envs/gold_pipelines\" then you should be okay. If it's something else then you should try uninstalling jupyter:\n",
    "\n",
    "```python\n",
    "conda remove jupyter jupyter-client jupyter-console jupyter-core\n",
    "\n",
    "conda uninstall jupyter_core nbformat nbconvert notebook\n",
    "```\n",
    "\n",
    "Then reinstall the gold_pipelines environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.widgets as sw\n",
    "from AODR_session_sorters import OpenEphysSessionSorter as OES\n",
    "from pyramid import cli\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define the relevant paths. You should change these to match the corresponding paths on your machine. If you encounter issues while loading/sorting the file, chances are that your computer is having a hard time accessing the files from cloud storage. If that is the case, you need to transfer your files to a local directory, and also save the files to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment directory top level - should contain the subfolders like ecodes, python, matlab.\n",
    "expDir = \"/Users/lowell/Documents/GitHub/Lab_Pipelines/experiments/aodr\"\n",
    "sessDir = \"MrM_2025-10-03_13-29-04\" #\"MrM_2025-09-26-Trimmed\"\n",
    "os.chdir(expDir) # regular python files will run from the first open folder in your tree, but notebooks will work from wherever the notebook is stored.\n",
    "# Directory where the raw files are stored to be converted/sorted\n",
    "dataSearchPath = \"/Users/lowell/Library/CloudStorage/Box-Box/GoldLab/Data/Physiology/AODR/dlPFC/MrM/Raw/Neuronal/SingleEL/\"\n",
    "# Where the rules for ecodes are stored\n",
    "pyramidSearchPath = expDir+\"/ecodes\"\n",
    "# Conversion specifications\n",
    "convertSpecs = expDir+\"/AODR_experiment_LC.yaml\"\n",
    "# Base directory to save the output files from pyramid (hdf5 files)\n",
    "baseSaveDir = \"/Users/lowell/Library/CloudStorage/Box-Box/GoldLab/Data/Physiology/AODR/dlPFC/MrM/Converted/Pyramid/Neuronal/SingleEL/\"\n",
    "# The Open Ephys experiment name\n",
    "currentFile = \"experiment1.nwb\"\n",
    "# Full directory to save the output files from pyramid (hdf5 files)\n",
    "trialFileOutputName = baseSaveDir+sessDir+\".hdf5\"\n",
    "# Directory to save the output files from sorting\n",
    "sorted_out = '/Users/lowell/Library/CloudStorage/Box-Box/GoldLab/Data/Physiology/AODR/dlPFC/MrM/Sorted/SingleEL/'+sessDir+\"/\"\n",
    "\n",
    "sys.path.append(expDir+\"/python\") # to make sure pyramid can access the custom collectors/enhancers/functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we run the sorter/analyzer. With ~4 channels of neural data and a 90 min recording, this should take between 10-20 minutes. The step_names variable defines the sequential processing steps that are defined as methods in AODR_session_sorters OpenEphysSessionSorter class. If you use the step \"open_sigui\", a gui window will open that allows to interact with the sorting results. Close the gui to continue to the next step and save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_tree ...OK\n",
      "read_data ...OK\n",
      "set_single ...OK\n",
      "bandpass ...OK\n",
      "Warning! The recording is already filtered, but mountainsort5 filter is enabled\n",
      "filtering\n",
      "whitening\n",
      "write_binary_recording \n",
      "n_jobs=12 - samples_per_chunk=29,999 - chunk_memory=117.18 KiB - total_memory=1.37 MiB - chunk_duration=1.00s (999.97 ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52c4c6a771747ef9a71f8db198a53af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording:   0%|          | 0/5932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    }
   ],
   "source": [
    "sorter = OES(session_dir=dataSearchPath+sessDir+\"/\", channel_names=[1],\n",
    "             out_folder=sorted_out,\n",
    "             stream_name='acquisition_board',\n",
    "             overwrite_timestamps=True,             # This will overwrite the first sample time in the phy params.py file since the first sample number has non-zero time\n",
    "             sorter_name='single_channel',\n",
    "             step_names=[\n",
    "                 'clean_tree',                      # This removes everything from the output folder!!!\n",
    "                 'read_data',                       # Has to be included to do anything else\n",
    "                 'set_single',\n",
    "                 'bandpass',\n",
    "                 'single_ch_sorter_and_analyzer',     # Runs one spike sorter which is an optional parameter (default spikecyrcus2) and one analyzer\n",
    "                 'open_sigui',                      # Opens a gui to view the sorting results to help with manual refinement\n",
    "                 'export_to_phy'                    # Currently pyramid supports Phy output or plexon\n",
    "             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike interface has a lot of widgets availble to use with python jupyter notebooks. These widgets are interactive and useful, and the below code will test whether they are working appropriately on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts_filt = sw.plot_spikes_on_traces(sorter.sorting_analyzer, channel_ids=[1], backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run Pyramid on the corresponding output to create a TrialFile. Make sure that the phy_reader.params_file points to the appropriate directory based on those you have defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli.main([\"convert\", \n",
    "        \"--trial-file\", trialFileOutputName, \n",
    "        \"--search-path\", pyramidSearchPath, \n",
    "        \"--experiment\", convertSpecs, \n",
    "        \"--readers\", \n",
    "        \"ttl_reader.session_dir=\"+dataSearchPath+sessDir,\n",
    "        \"message_reader.session_dir=\"+dataSearchPath+sessDir,\n",
    "        \"gaze_x_reader.session_dir=\"+dataSearchPath+sessDir,\n",
    "        \"gaze_y_reader.session_dir=\"+dataSearchPath+sessDir,\n",
    "        \"pupil_reader.session_dir=\"+dataSearchPath+sessDir,\n",
    "        \"phy_reader.params_file=\"+sorted_out+\"/phy/params.py\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gold_pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
